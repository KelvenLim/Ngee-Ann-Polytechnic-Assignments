{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a id = \"top\"></a>\n",
    "\n",
    "### 0. [Import Libraries](#0)\n",
    "\n",
    "### 1. [HR Analytics](#1)\n",
    "- [1.1 Load and Explore the data](#1.1)\n",
    "- [1.2 Build the Model(s)](#1.2)\n",
    "    - [1.2.1 Logistic Classifier](#1.2.1)\n",
    "    - [1.2.2 DecisionTreeClassifier](#1.2.2)\n",
    "    - [1.2.3 MLPClassifier](#1.2.3)\n",
    "    - [1.2.4 RandomForestClassifier](#1.2.4)\n",
    "    - [1.2.5 BaggingClassifier](#1.2.5)\n",
    "    - [1.2.6 AdaBoostClassifier](#1.2.6)\n",
    "    - [1.2.7 XGBClassifier](#1.2.7)\n",
    "    - [1.2.8 SVC](#1.2.8)\n",
    "    - [1.2.9 VotingClassifier](#1.2.9)\n",
    "- [1.3 Evaluate and Improve the Model(s)](#1.3)\n",
    "    - [1.3.1 Logistic Classifier](#1.3.1)\n",
    "    - [1.3.2 DecisionTreeClassifier](#1.3.2)\n",
    "    - [1.3.3 MLPClassifier](#1.3.3)\n",
    "    - [1.3.4 RandomForestClassifier](#1.3.4)\n",
    "    - [1.3.5 BaggingClassifier](#1.3.5)\n",
    "    - [1.3.6 AdaBoostClassifier](#1.3.6)\n",
    "    - [1.3.7 XGBClassifier](#1.3.7)\n",
    "    - [1.3.8 SVC](#1.3.8)\n",
    "    - [1.3.9 VotingClassifier](#1.3.9)\n",
    "\n",
    "### 2. [Airbnb](#2)\n",
    "- [2.1 Load and Explore the data](#2.1)\n",
    "- [2.2 Build the Model(s)](#2.2)\n",
    "    - [2.2.1 Linear Regressor](#2.2.1)\n",
    "    - [2.2.2 DecisionTreeRegressor](#2.2.2)\n",
    "    - [2.2.3 MLPRegressor](#2.2.3)\n",
    "    - [2.2.4 RandomForestRegressor](#2.2.4)\n",
    "    - [2.2.5 BaggingRegressor](#2.2.5)\n",
    "    - [2.2.6 AdaBoostRegressor](#2.2.6)\n",
    "    - [2.2.7 XGBRegressor](#2.2.7)\n",
    "    - [2.2.8 SVRRegressor](#2.2.8)\n",
    "    - [2.2.9 VotingRegressor](#2.2.9)\n",
    "- [2.3 Evaluate and Improve the Model(s)](#2.3)\n",
    "    - [2.3.1 Linear Regressor](#2.3.1)\n",
    "    - [2.3.2 DecisionTreeRegressor](#2.3.2)\n",
    "    - [2.3.3 MLPRegressor](#2.3.3)\n",
    "    - [2.3.4 RandomForestRegressor](#2.3.4)\n",
    "    - [2.3.5 BaggingRegressor](#2.3.5)\n",
    "    - [2.3.6 AdaBoostRegressor](#2.3.6)\n",
    "    - [2.3.7 XGBRegressor](#2.3.7)\n",
    "    - [2.3.8 SVRRegressor](#2.3.8)\n",
    "    - [2.3.9 VotingRegressor](#2.3.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Libraries <a id = \"0\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import warnings to turn off warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Regressors\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# Multi-layer classifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "# Ensemble learning\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingRegressor, BaggingClassifier, AdaBoostClassifier, AdaBoostRegressor, VotingClassifier, VotingRegressor\n",
    "\n",
    "# XGBClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# GridSearch\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. HR Analytics <a id = \"1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load and Sample the data <a id = \"1.1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target column = is_promoted\n",
    "# 0 = not promoted\n",
    "# 1 = promoted\n",
    "\n",
    "hr_xtrain = pd.read_csv('./data/hr_final_Xtrain.csv')\n",
    "hr_xtest = pd.read_csv('./data/hr_final_Xtest.csv')\n",
    "\n",
    "hr_ytrain = pd.read_csv('./data/hr_final_ytrain.csv')\n",
    "hr_ytest = pd.read_csv('./data/hr_final_ytest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Build the Model(s) <a id = \"1.2\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Logistic Classifier <a id = \"1.2.1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "lg = LogisticRegression(solver = 'lbfgs', max_iter = 10000, random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "lg.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 DecisionTreeClassifier <a id = \"1.2.2\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "dtc = DecisionTreeClassifier(max_depth = 2, random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "dtc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 MLPClassifier <a id = \"1.2.3\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10,), max_iter=2000, random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "mlpc = MLPClassifier(hidden_layer_sizes = (10,), max_iter = 2000, random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "mlpc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 RandomForestClassifier <a id = \"1.2.4\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "rfc = RandomForestClassifier(n_estimators = 10, max_depth = 4, random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "rfc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 BaggingClassifier <a id = \"1.2.5\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "bgc = BaggingClassifier(n_estimators = 10, random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "bgc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 AdaBoostClassifier <a id = \"1.2.6\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
       "                   learning_rate=0.1, n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "adbc = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 3), n_estimators = 10, learning_rate = 0.1, random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "adbc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 XGBClassifier <a id = \"1.2.7\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=20, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "xgbc = XGBClassifier(n_estimators = 20, learning_rate = 0.1, eval_metric = 'logloss', random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "xgbc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.8 SVC <a id = \"1.2.8\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.8, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "svc = SVC(C = 0.8, kernel = 'rbf', random_state = 0)\n",
    "# test C, kernal\n",
    "\n",
    "# Fit the model\n",
    "svc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.9 VotingClassifier <a id = \"1.2.9\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dtc',\n",
       "                              DecisionTreeClassifier(max_depth=2,\n",
       "                                                     random_state=0)),\n",
       "                             ('mlpc',\n",
       "                              MLPClassifier(hidden_layer_sizes=(10,),\n",
       "                                            max_iter=2000, random_state=0)),\n",
       "                             ('rfc',\n",
       "                              RandomForestClassifier(max_depth=4,\n",
       "                                                     n_estimators=10,\n",
       "                                                     random_state=0)),\n",
       "                             ('bgc', BaggingClassifier(random_state=0)),\n",
       "                             ('adbc',\n",
       "                              AdaBoostClassifier(base_estimator=DecisionTreeClassifier(ma...\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.1, max_delta_step=0,\n",
       "                                            max_depth=6, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=20, n_jobs=12,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=0,\n",
       "                                            reg_alpha=0, reg_lambda=1,\n",
       "                                            scale_pos_weight=1, subsample=1,\n",
       "                                            tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None)),\n",
       "                             ('svc', SVC(C=0.8, random_state=0))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "vc = VotingClassifier(estimators = [('dtc', dtc), ('mlpc', mlpc), ('rfc', rfc), \n",
    "                                    ('bgc', bgc), ('adbc', adbc), ('xgbc', xgbc), ('svc', svc)], \n",
    "                      voting = 'hard')\n",
    "\n",
    "# Fit the model\n",
    "vc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Evaluate and Improve the Model(s) <a id = \"1.3\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Logistic Classifier <a id = \"1.3.1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7364957918898241\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = lg.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = lg.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7346560920896732\n",
      "{'max_iter': 25, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {\"solver\": ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "              \"max_iter\": [25, 50, 75, 100, 125, 150, 175]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(lg, param_grid = param_grid, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "\n",
    "gs = gs.fit(hr_xtrain, hr_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=25, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "lg = LogisticRegression(solver = 'lbfgs', \n",
    "                        max_iter = 25, \n",
    "                        random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "lg.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7364957918898241\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = lg.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = lg.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 DecisionTreeClassifier <a id = \"1.3.2\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.6910482019892884\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = dtc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = dtc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7801099137830103\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {\"criterion\" : [\"gini\", \"entropy\"], \n",
    "              'splitter': ['best', 'random'],\n",
    "              \"min_samples_leaf\" : [1, 2, 3, 4, 5], \n",
    "              \"min_samples_split\" : [2, 4, 6, 8, 10], \n",
    "              'max_depth' : [None, 1, 2, 3, 4, 5]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(dtc, param_grid = param_grid, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "gs = gs.fit(hr_xtrain, hr_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', min_samples_leaf=5, random_state=0,\n",
       "                       splitter='random')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "dtc = DecisionTreeClassifier(criterion = 'entropy', \n",
    "                             max_depth = None, \n",
    "                             min_samples_leaf = 5, \n",
    "                             min_samples_split = 2,\n",
    "                             splitter = 'random',\n",
    "                             random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "dtc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8465187452180566\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = dtc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = dtc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 MLPClassifier <a id = \"1.3.3\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7935730680948737\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = mlpc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = mlpc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8006120887528692\n",
      "{'activation': 'relu', 'hidden_layer_sizes': (150,), 'learning_rate': 'constant', 'max_iter': 300, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {\"activation\": ['logistic', 'relu', 'identity','relu'],\n",
    "              'hidden_layer_sizes': [(50,),(100,),(150,)],\n",
    "              'learning_rate':['constant','invscaling','adaptive'],\n",
    "              'max_iter': [100,200,300],\n",
    "              'solver': ['sgd', 'adam']\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(mlpc, param_grid = param_grid, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(hr_xtrain, hr_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(150,), max_iter=300, random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "mlpc = MLPClassifier(activation = 'relu', \n",
    "                     hidden_layer_sizes = (150,), \n",
    "                     learning_rate = 'constant',\n",
    "                     max_iter = 300, \n",
    "                     solver = 'adam', \n",
    "                     random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "mlpc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8125478194338179\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = mlpc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = mlpc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 RandomForestClassifier <a id = \"1.3.4\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7690895179801072\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = rfc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = rfc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7677123182861514\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {\"criterion\" : [\"gini\", \"entropy\"], \n",
    "              \"max_depth\": [1,2,3,4,5], \n",
    "              'min_samples_split':[2,3,4,5],\n",
    "              \"min_samples_leaf\" : [1,2,3,4,5], \n",
    "              \"n_estimators\": [25,50,100,125,150]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = rfc, param_grid = param_grid, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(hr_xtrain, hr_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_leaf=4, n_estimators=150,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "rfc = RandomForestClassifier(criterion = 'gini', \n",
    "                             n_estimators = 150, \n",
    "                             max_depth = 5, \n",
    "                             min_samples_leaf = 4, \n",
    "                             min_samples_split = 2,\n",
    "                             random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "rfc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7684774292272379\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = rfc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = rfc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 BaggingClassifier <a id = \"1.3.5\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9827084927314461\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = bgc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = bgc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6587605202754399\n",
      "{'max_features': 3, 'max_samples': 5, 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'max_samples': [1,2,3,4,5],\n",
    "              'max_features': [1,2,3,4,5],\n",
    "              \"n_estimators\": [5, 10, 15, 20, 25]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = bgc, param_grid = param_grid, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(hr_xtrain, hr_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(max_features=3, max_samples=5, n_estimators=25,\n",
       "                  random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "bgc = BaggingClassifier(n_estimators = 25, \n",
    "                        max_features = 3, \n",
    "                        max_samples = 5, \n",
    "                        random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "bgc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.6306044376434583\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = bgc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = bgc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.6 AdaBoostClassifier <a id = \"1.3.6\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7951032899770467\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = adbc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = adbc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8120887528691659\n",
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.1, 'n_estimators': 125}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'learning_rate': [0.1, 0.5, 1, 1.5, 2],\n",
    "              \"n_estimators\": [25,50,75,100,125],\n",
    "              'algorithm': [\"SAMME\", \"SAMME.R\"]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = adbc, param_grid = param_grid, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(hr_xtrain, hr_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',\n",
       "                                                         min_samples_leaf=5,\n",
       "                                                         random_state=0,\n",
       "                                                         splitter='random'),\n",
       "                   learning_rate=0.1, n_estimators=125, random_state=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "adbc = AdaBoostClassifier(dtc, \n",
    "                          n_estimators = 125, \n",
    "                          learning_rate = 0.1, \n",
    "                          algorithm = 'SAMME.R', \n",
    "                          random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "adbc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9935730680948738\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = adbc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = adbc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.7 XGBClassifier <a id = \"1.3.7\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8180566182096404\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = xgbc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = xgbc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125478194338178\n",
      "{'eval_metric': 'logloss', 'learning_rate': 0.5, 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'learning_rate': [0.1, 0.3, 0.5, 1],\n",
    "              'max_depth':[2,4,6,8,10],\n",
    "              'eval_metric': ['logloss', 'rmse', 'mae']\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = xgbc, param_grid = param_grid, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(hr_xtrain, hr_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.5, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "xgbc = XGBClassifier(learning_rate = 0.5, \n",
    "                     eval_metric = 'logloss', \n",
    "                     max_depth = 4,\n",
    "                     random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "xgbc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8800306044376435\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = xgbc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = xgbc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.8 SVC <a id = \"1.3.8\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7860749808722265\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = svc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = svc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7869931140015302\n",
      "{'C': 1.5, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'C': [0.5, 0.75, 1, 1.25, 1.5],\n",
    "              \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              'gamma': ['scale', 'auto']\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = svc, param_grid = param_grid, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(hr_xtrain, hr_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.5, random_state=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "svc = SVC(C = 1.5, \n",
    "          kernel = 'rbf', \n",
    "          gamma = 'scale', \n",
    "          random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "svc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7918898240244836\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = svc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = svc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.9 VotingClassifier <a id = \"1.3.9\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8012241775057384\n",
      "Testing accuracy: 0.5080328454123527\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = vc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = vc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dtc',\n",
       "                              DecisionTreeClassifier(criterion='entropy',\n",
       "                                                     min_samples_leaf=5,\n",
       "                                                     random_state=0,\n",
       "                                                     splitter='random')),\n",
       "                             ('mlpc',\n",
       "                              MLPClassifier(hidden_layer_sizes=(150,),\n",
       "                                            max_iter=300, random_state=0)),\n",
       "                             ('rfc',\n",
       "                              RandomForestClassifier(max_depth=5,\n",
       "                                                     min_samples_leaf=4,\n",
       "                                                     n_estimators=150,\n",
       "                                                     random_state=0)),\n",
       "                             ('bgc',\n",
       "                              BaggingClassifier(max_features=3, max_...\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.5, max_delta_step=0,\n",
       "                                            max_depth=4, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=12,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=0,\n",
       "                                            reg_alpha=0, reg_lambda=1,\n",
       "                                            scale_pos_weight=1, subsample=1,\n",
       "                                            tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None)),\n",
       "                             ('svc', SVC(C=1.5, random_state=0))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "vc = VotingClassifier(estimators = [('dtc', dtc), ('mlpc', mlpc), ('rfc', rfc), \n",
    "                                    ('bgc', bgc), ('adbc', adbc), ('xgbc', xgbc), ('svc', svc)], \n",
    "                      voting = 'hard')\n",
    "\n",
    "# Fit the model\n",
    "vc.fit(hr_xtrain, hr_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8485080336648814\n",
      "Testing accuracy: 0.5080328454123527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = vc.score(hr_xtrain, hr_ytrain)\n",
    "test_acc = vc.score(hr_xtest, hr_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Airbnb <a id = \"2\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load and Sample the data <a id = \"2.1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target column = price\n",
    "\n",
    "airbnb_xtrain = pd.read_csv('./data/airbnb_final_Xtrain.csv')\n",
    "airbnb_xtest = pd.read_csv('./data/airbnb_final_Xtest.csv')\n",
    "\n",
    "airbnb_ytrain = pd.read_csv('./data/airbnb_final_ytrain.csv')\n",
    "airbnb_ytest = pd.read_csv('./data/airbnb_final_ytest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Build the Model(s) <a id = \"2.2\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Linear Regressor <a id = \"2.2.1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "lm.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 DecisionTreeRegressor <a id = \"2.2.2\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "dtr = DecisionTreeRegressor(max_depth = 2, \n",
    "                            random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "dtr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 MLPRegressor <a id = \"2.2.3\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(10,), max_iter=2000, random_state=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "mlpr = MLPRegressor(hidden_layer_sizes = (10,), \n",
    "                    max_iter = 2000, \n",
    "                    random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "mlpr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 RandomForestRegressor <a id = \"2.2.4\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=4, n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "rfr = RandomForestRegressor(n_estimators = 10, \n",
    "                            max_depth = 4, \n",
    "                            random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "rfr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 BaggingRegressor <a id = \"2.2.5\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(random_state=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "bgr = BaggingRegressor(n_estimators = 10, \n",
    "                       random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "bgr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 AdaBoostRegressor <a id = \"2.2.6\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=2,\n",
       "                                                       random_state=0),\n",
       "                  learning_rate=0.1, n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "adbr = AdaBoostRegressor(dtr, \n",
    "                         n_estimators = 10, \n",
    "                         learning_rate = 0.1, \n",
    "                         random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "adbr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.7 XGBRegressor <a id = \"2.2.7\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             eval_metric='logloss', gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=20, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "xgbr = XGBRegressor(n_estimators = 20, \n",
    "                    learning_rate = 0.1, \n",
    "                    eval_metric = 'logloss', \n",
    "                    random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "xgbr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.8 SVR <a id = \"2.2.8\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=0.8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "svr = SVR(C = 0.8, kernel = 'rbf')\n",
    "\n",
    "# Fit the model\n",
    "svr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.9 VotingRegressor <a id = \"2.2.9\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('dtr',\n",
       "                             DecisionTreeRegressor(max_depth=2,\n",
       "                                                   random_state=0)),\n",
       "                            ('mlpr',\n",
       "                             MLPRegressor(hidden_layer_sizes=(10,),\n",
       "                                          max_iter=2000, random_state=0)),\n",
       "                            ('rfr',\n",
       "                             RandomForestRegressor(max_depth=4, n_estimators=10,\n",
       "                                                   random_state=0)),\n",
       "                            ('bgr', BaggingRegressor(random_state=0)),\n",
       "                            ('adbr',\n",
       "                             AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth...\n",
       "                                          gpu_id=-1, importance_type=None,\n",
       "                                          interaction_constraints='',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=6, min_child_weight=1,\n",
       "                                          missing=nan,\n",
       "                                          monotone_constraints='()',\n",
       "                                          n_estimators=20, n_jobs=12,\n",
       "                                          num_parallel_tree=1, predictor='auto',\n",
       "                                          random_state=0, reg_alpha=0,\n",
       "                                          reg_lambda=1, scale_pos_weight=1,\n",
       "                                          subsample=1, tree_method='exact',\n",
       "                                          validate_parameters=1,\n",
       "                                          verbosity=None)),\n",
       "                            ('svr', SVR(C=0.8))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "vr = VotingRegressor(estimators = [('dtr', dtr), ('mlpr', mlpr), ('rfr', rfr), \n",
    "                                    ('bgr', bgr), ('adbr', adbr), ('xgbr', xgbr), ('svr', svr)])\n",
    "\n",
    "# Fit the model\n",
    "vr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Evaluate and Improve the Model(s) <a id = \"2.3\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 LinearRegressor <a id = \"2.3.1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.057399293521222305\n",
      "Testing accuracy: -1145.7546145421225\n",
      "\n",
      "the training mean squared error is: 104565.41385857265\n",
      "the testing mean squared error is: 145477666.13345268\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = lm.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = lm.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(lm.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(lm.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 DecisionTreeRegressor <a id = \"2.3.2\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.16363243485508594\n",
      "Testing accuracy: -0.021580178126967775\n",
      "\n",
      "the training mean squared error is: 92780.66522352397\n",
      "the testing mean squared error is: 129597.99611658695\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = dtr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = dtr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(dtr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(dtr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06047986105585419\n",
      "{'criterion': 'poisson', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'criterion': ['friedman_mse', 'poisson'],\n",
    "              \"splitter\": ['best', 'random'],\n",
    "              'max_depth': [2, 3, 4, 5],\n",
    "              'min_samples_split': [2,3,4],\n",
    "              'min_samples_leaf': [1,2,3]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = dtr, param_grid = param_grid, scoring = 'r2', cv = 5, n_jobs = -1, error_score = 'raise')\n",
    "gs = gs.fit(airbnb_xtrain, airbnb_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='poisson', max_depth=5, min_samples_split=3,\n",
       "                      random_state=0, splitter='random')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "dtr = DecisionTreeRegressor(criterion = 'poisson', \n",
    "                            splitter = 'random', \n",
    "                            max_depth = 5, \n",
    "                            min_samples_leaf = 1,\n",
    "                            min_samples_split = 3,\n",
    "                            random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "dtr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.17071716165148576\n",
      "Testing accuracy: 0.0175466341511199\n",
      "\n",
      "the training mean squared error is: 91994.73605494962\n",
      "the testing mean squared error is: 124634.35589114024\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = dtr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = dtr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(dtr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(dtr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 MLPRegressor <a id = \"2.3.3\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.06806817809812504\n",
      "Testing accuracy: -2372.5903084999773\n",
      "\n",
      "the training mean squared error is: 103381.88373439033\n",
      "the testing mean squared error is: 301114444.24004537\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = mlpr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = mlpr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(mlpr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(mlpr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08297406351508259\n",
      "{'activation': 'relu', 'hidden_layer_sizes': (90,), 'learning_rate': 'adaptive', 'max_iter': 100, 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {\"activation\": ['logistic', 'relu', 'identity','tanh'],\n",
    "              'hidden_layer_sizes': [(90,), (100,), (110,)],\n",
    "              'max_iter': [100, 200, 300],\n",
    "              'solver': ['sgd', 'adam'],\n",
    "              'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(mlpr, param_grid = param_grid, scoring = 'r2', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(airbnb_xtrain, airbnb_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(90,), learning_rate='adaptive', max_iter=100,\n",
       "             random_state=0, solver='sgd')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "mlpr = MLPRegressor(activation = 'relu', \n",
    "                    hidden_layer_sizes = (90,), \n",
    "                    learning_rate = 'adaptive',\n",
    "                    max_iter = 100, \n",
    "                    solver = 'sgd', \n",
    "                    random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "mlpr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.17077675575449436\n",
      "Testing accuracy: -15877063.637383914\n",
      "\n",
      "the training mean squared error is: 91988.12510929491\n",
      "the testing mean squared error is: 2014169621997.8398\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = mlpr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = mlpr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(mlpr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(mlpr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 RandomForestRegressor <a id = \"2.3.4\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.2880554769480188\n",
      "Testing accuracy: -1.8895565241443633\n",
      "\n",
      "the training mean squared error is: 78978.05845634663\n",
      "the testing mean squared error is: 366570.0874123432\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = rfr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = rfr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(rfr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(rfr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09011808002126782\n",
      "{'criterion': 'friedman_mse', 'max_depth': 5, 'min_samples_leaf': 4, 'n_estimators': 90}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'criterion': ['friedman_mse', 'absolute_error', 'poisson'],\n",
    "              'n_estimators': [90, 100, 200, 300],\n",
    "              \"max_depth\": [1, 2, 3, 4, 5], \n",
    "              \"min_samples_leaf\" : [1, 2, 3, 4, 5]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(rfr, param_grid = param_grid, scoring = 'r2', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(airbnb_xtrain, airbnb_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(criterion='friedman_mse', max_depth=5, min_samples_leaf=4,\n",
       "                      n_estimators=90, random_state=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "rfr = RandomForestRegressor(criterion = 'friedman_mse', \n",
    "                            max_depth = 5,\n",
    "                            min_samples_leaf = 4, \n",
    "                            n_estimators = 90, \n",
    "                            random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "rfr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.2239200577669188\n",
      "Testing accuracy: -0.30442129085139213\n",
      "\n",
      "the training mean squared error is: 86092.78540654943\n",
      "the testing mean squared error is: 165479.31234932548\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = rfr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = rfr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(rfr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(rfr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 BaggingRegressor <a id = \"2.3.5\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.769126940854773\n",
      "Testing accuracy: -1.9107598079363632\n",
      "\n",
      "the training mean squared error is: 25611.41405091756\n",
      "the testing mean squared error is: 369259.9429414243\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = bgr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = bgr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(bgr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(bgr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030682993925259062\n",
      "{'max_features': 4, 'max_samples': 4, 'n_estimators': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'max_samples': [1, 2, 3, 4, 5],\n",
    "              'max_features': [1, 2, 3, 4, 5],\n",
    "              \"n_estimators\": [5, 10, 15, 20, 25]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = bgr, param_grid = param_grid, scoring = 'r2', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(airbnb_xtrain, airbnb_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(max_features=4, max_samples=4, n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "bgr = BaggingRegressor(max_features = 4, \n",
    "                       max_samples = 4, \n",
    "                       n_estimators = 5, \n",
    "                       random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "bgr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.022273973107930334\n",
      "Testing accuracy: -0.0001434429748456978\n",
      "\n",
      "the training mean squared error is: 108461.9669172389\n",
      "the testing mean squared error is: 126878.5248714707\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = bgr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = bgr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(bgr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(bgr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 AdaBoostRegressor <a id = \"2.3.6\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.07912478090447972\n",
      "Testing accuracy: -1.1596883787934331e-05\n",
      "\n",
      "the training mean squared error is: 102155.34290923514\n",
      "the testing mean squared error is: 126861.79883315992\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = adbr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = adbr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(adbr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(adbr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21006618021213946\n",
      "{'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'learning_rate': [0.1, 0.5, 1, 1.5, 2],\n",
    "              \"n_estimators\": [25, 50, 75, 100, 125],\n",
    "              'loss': [\"linear\", \"square\", 'exponential']\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = adbr, param_grid = param_grid, scoring = 'r2', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(airbnb_xtrain, airbnb_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='poisson',\n",
       "                                                       max_depth=5,\n",
       "                                                       min_samples_split=3,\n",
       "                                                       random_state=0,\n",
       "                                                       splitter='random'),\n",
       "                  learning_rate=0.1, loss='exponential', n_estimators=25,\n",
       "                  random_state=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "adbr = AdaBoostRegressor(dtr, learning_rate = 0.1, \n",
    "                         loss = 'exponential', \n",
    "                         n_estimators = 25, \n",
    "                         random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "adbr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.28552646344773724\n",
      "Testing accuracy: 0.003399460909406238\n",
      "\n",
      "the training mean squared error is: 79258.6092150011\n",
      "the testing mean squared error is: 126429.07092388671\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = adbr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = adbr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(adbr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(adbr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.7 XGBRegressor <a id = \"2.3.7\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5375175453802377\n",
      "Testing accuracy: -0.051553837574127126\n",
      "\n",
      "the training mean squared error is: 51304.51201368031\n",
      "the testing mean squared error is: 133400.46437488362\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = xgbr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = xgbr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(xgbr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(xgbr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042783151473505976\n",
      "{'eval_metric': 'logloss', 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50, 'sampling_method': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'learning_rate': [0.1, 0.3, 0.5, 1, 1.5],\n",
    "              'max_depth':[1,4,6,8,10],\n",
    "              'sampling_method':['uniform','subsample','gradient_based'],\n",
    "              \"n_estimators\": [50, 100, 200, 300, 400],\n",
    "              'eval_metric': [\"logloss\", \"mae\"]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = xgbr, param_grid = param_grid, scoring = 'r2', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(airbnb_xtrain, airbnb_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             eval_metric='logloss', gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=1, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=50, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, sampling_method='uniform', scale_pos_weight=1,\n",
       "             subsample=1, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "xgbr = XGBRegressor(n_estimators = 50, \n",
    "                    learning_rate = 0.1, \n",
    "                    eval_metric = 'logloss', \n",
    "                    max_depth = 1,\n",
    "                    sampling_method = 'uniform',\n",
    "                    random_state = 0)\n",
    "\n",
    "# Fit the model\n",
    "xgbr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.09262478979739786\n",
      "Testing accuracy: -0.06458255917599587\n",
      "\n",
      "the training mean squared error is: 100657.7480026328\n",
      "the testing mean squared error is: 135053.29226614017\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = xgbr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = xgbr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(xgbr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(xgbr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.8 SVR <a id = \"2.3.8\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.019479039485357785\n",
      "Testing accuracy: -0.045289786278011945\n",
      "\n",
      "the training mean squared error is: 108772.01696169865\n",
      "the testing mean squared error is: 132605.80477505032\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = svr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = svr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(svr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(svr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0326425334921711\n",
      "{'C': 1.5, 'degree': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearch model to find the best parameters\n",
    "\n",
    "param_grid = {'C': [0.5, 0.75, 1, 1.25, 1.5],\n",
    "              \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              'gamma': ['scale', 'auto'],\n",
    "              'degree': [1,2,3,4,5]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(estimator = svr, param_grid = param_grid, scoring = 'r2', cv = 5, n_jobs = -1)\n",
    "gs = gs.fit(airbnb_xtrain, airbnb_ytrain)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.5, degree=1, kernel='linear')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "svr = SVR(C = 1.5, \n",
    "          degree = 1,\n",
    "          gamma = 'scale', \n",
    "          kernel = 'linear')\n",
    "\n",
    "# Fit the model\n",
    "svr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.024363139335722317\n",
      "Testing accuracy: -264.08256148502517\n",
      "\n",
      "the training mean squared error is: 108230.20968458788\n",
      "the testing mean squared error is: 33628460.603942424\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = svr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = svr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(svr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(svr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.9 VotingRegressor <a id = \"2.3.9\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.3713045142942796\n",
      "Testing accuracy: -52.75304308905891\n",
      "\n",
      "the training mean squared error is: 69743.0027391085\n",
      "the testing mean squared error is: 6819128.658391783\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = vr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = vr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(vr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(vr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('dtr',\n",
       "                             DecisionTreeRegressor(criterion='poisson',\n",
       "                                                   max_depth=5,\n",
       "                                                   min_samples_split=3,\n",
       "                                                   random_state=0,\n",
       "                                                   splitter='random')),\n",
       "                            ('mlpr',\n",
       "                             MLPRegressor(hidden_layer_sizes=(90,),\n",
       "                                          learning_rate='adaptive',\n",
       "                                          max_iter=100, random_state=0,\n",
       "                                          solver='sgd')),\n",
       "                            ('rfr',\n",
       "                             RandomForestRegressor(criterion='friedman_mse',\n",
       "                                                   max_depth=5,\n",
       "                                                   min_samples_leaf=4,\n",
       "                                                   n_estim...\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=1, min_child_weight=1,\n",
       "                                          missing=nan,\n",
       "                                          monotone_constraints='()',\n",
       "                                          n_estimators=50, n_jobs=12,\n",
       "                                          num_parallel_tree=1, predictor='auto',\n",
       "                                          random_state=0, reg_alpha=0,\n",
       "                                          reg_lambda=1,\n",
       "                                          sampling_method='uniform',\n",
       "                                          scale_pos_weight=1, subsample=1,\n",
       "                                          tree_method='exact',\n",
       "                                          validate_parameters=1,\n",
       "                                          verbosity=None)),\n",
       "                            ('svr', SVR(C=1.5, degree=1, kernel='linear'))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "vr = VotingRegressor(estimators = [('dtr', dtr), ('mlpr', mlpr), ('rfr', rfr), \n",
    "                                    ('bgr', bgr), ('adbr', adbr), ('xgbr', xgbr), ('svr', svr)])\n",
    "\n",
    "# Fit the model\n",
    "vr.fit(airbnb_xtrain, airbnb_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.18007681875870396\n",
      "Testing accuracy: -326669.5552903266\n",
      "\n",
      "the training mean squared error is: 90956.44230844197\n",
      "the testing mean squared error is: 41441533677.30801\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "train_acc = vr.score(airbnb_xtrain, airbnb_ytrain)\n",
    "test_acc = vr.score(airbnb_xtest, airbnb_ytest)\n",
    "\n",
    "print(f'Training accuracy: {train_acc}')\n",
    "print(f'Testing accuracy: {test_acc}')\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "train_mse = mean_squared_error(vr.predict(airbnb_xtrain), airbnb_ytrain)\n",
    "test_mse = mean_squared_error(vr.predict(airbnb_xtest), airbnb_ytest)\n",
    "\n",
    "print(f'the training mean squared error is: {train_mse}')\n",
    "print(f'the testing mean squared error is: {test_mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
