{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"width:250px\"><img src='https://www.np.edu.sg/images/default-source/default-album/img-logo.png?sfvrsn=764583a6_0' style=\"width: 100%; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Distributed Data Pipelines</h1><h2>Assignment 1 </h2><h3>Diploma in Data Science</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Objectives:\n",
    "- Design PySpark Based Machine Learning\n",
    "- Execute PySpark Syntax Correctly\n",
    "- Evaluate and Select Final Model based on Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be **graded on the use of PySpark**, so usage of **Pandas itself should be avoided as much as possible**, especially if a particular native method or function is already available in PySpark. **Penalties will be imposed in such cases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a id = \"top\"></a>\n",
    "\n",
    "### 0. [Import Libraries](#0)\n",
    "\n",
    "### 1. [Problem Statement Formulation](#1)\n",
    "\n",
    "### 2. [Exploratory Data Analysis and Data Cleansing](#2)\n",
    "\n",
    "### 3. [Data Wrangling and Transformation](#3)\n",
    "- [3.1 Remove Redundant Columns](#3.1)\n",
    "- [3.2 Outlier Removal](#3.2)\n",
    "- [3.2 Check for Rare Values](#3.3)\n",
    "- [3.3 StringIndex](#3.4)\n",
    "- [3.4 OHE](#3.5)\n",
    "- [3.5 Consolidating X columns](#3.6)\n",
    "- [3.6 Standard Scaling](#3.7)\n",
    "- [3.7 Train-test Split](#3.8)\n",
    "\n",
    "### 4. [Machine Learning Modelling](#4)\n",
    "\n",
    "### 5. [Model Evaluation and Selection](#5)\n",
    "\n",
    "### 6. [Report](#6)\n",
    "- [6.1 Problem Statement Formulation](#6.1)\n",
    "- [6.2 Exploratory Data Analysis and Data Cleansing](#6.2)\n",
    "- [6.3 Data Wrangling and Transformation](#6.3)\n",
    "- [6.4 Machine Learning Modelling](#6.4)\n",
    "- [6.5 Model Evaluation and Selection](#6.5)\n",
    "- [6.6 Summary and Further Improvements](#6.6)\n",
    "\n",
    "### 7. [\"Unlisted\" Youtube Link to Video Presentation](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Libraries <a id = \"0\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Imputer, OneHotEncoder, StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start session\n",
    "spark = SparkSession.builder.appName('DDP_ASG1').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem Statement Formulation <a id = \"1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What columns can be used to predict resale price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and explore data\n",
    "df = spark.read.csv('./data/sg_flat_prices_mod.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+---------------+------------+\n",
      "|year|month|      town|flat_type|block|      street_name|storey_range|floor_area_sqm|    flat_model|lease_commence_date|remaining_lease|resale_price|\n",
      "+----+-----+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+---------------+------------+\n",
      "|2017|    1|ANG MO KIO|   2 ROOM|  406|ANG MO KIO AVE 10|    10 TO 12|          44.0|      Improved|               1979|            736|    232000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  108| ANG MO KIO AVE 4|    01 TO 03|          67.0|New Generation|               1978|            727|    250000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  602| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|            749|    262000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  465|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1980|            745|    265000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  601| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|            749|    265000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  150| ANG MO KIO AVE 5|    01 TO 03|          68.0|New Generation|               1981|            756|    275000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  447|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1979|            738|    280000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  218| ANG MO KIO AVE 1|    04 TO 06|          67.0|New Generation|               1976|            700|    285000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  447|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1979|            738|    285000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  571| ANG MO KIO AVE 3|    01 TO 03|          67.0|New Generation|               1979|            736|    285000.0|\n",
      "+----+-----+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+---------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- town: string (nullable = true)\n",
      " |-- flat_type: string (nullable = true)\n",
      " |-- block: string (nullable = true)\n",
      " |-- street_name: string (nullable = true)\n",
      " |-- storey_range: string (nullable = true)\n",
      " |-- floor_area_sqm: double (nullable = true)\n",
      " |-- flat_model: string (nullable = true)\n",
      " |-- lease_commence_date: integer (nullable = true)\n",
      " |-- remaining_lease: integer (nullable = true)\n",
      " |-- resale_price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis and Data Cleansing  <a id = \"2\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---------+-----+-----------+------------+--------------+----------+-------------------+---------------+------------+\n",
      "|year|month|town|flat_type|block|street_name|storey_range|floor_area_sqm|flat_model|lease_commence_date|remaining_lease|resale_price|\n",
      "+----+-----+----+---------+-----+-----------+------------+--------------+----------+-------------------+---------------+------------+\n",
      "|   0|    0|   0|        0|    0|          0|           0|            50|         0|                  0|              0|           0|\n",
      "+----+-----+----+---------+-----+-----------+------------+--------------+----------+-------------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([f.count(f.when(f.isnan(c) | f.col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace nulls in floor_area_sqm with median\n",
    "imputer = Imputer(inputCols = ['floor_area_sqm'], \n",
    "                  outputCols = [\"floor_area_sqm_imputed\"]\n",
    "                 ).setStrategy(\"median\")\n",
    "\n",
    "# Add imputation cols to df\n",
    "df_imputed = imputer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---------+-----+-----------+------------+--------------+----------+-------------------+---------------+------------+----------------------+\n",
      "|year|month|town|flat_type|block|street_name|storey_range|floor_area_sqm|flat_model|lease_commence_date|remaining_lease|resale_price|floor_area_sqm_imputed|\n",
      "+----+-----+----+---------+-----+-----------+------------+--------------+----------+-------------------+---------------+------------+----------------------+\n",
      "|   0|    0|   0|        0|    0|          0|           0|            50|         0|                  0|              0|           0|                     0|\n",
      "+----+-----+----+---------+-----+-----------+------------+--------------+----------+-------------------+---------------+------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for nulls again\n",
    "df_imputed.select([f.count(f.when(f.isnan(c) | f.col(c).isNull(), c)).alias(c) for c in df_imputed.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Wrangling and Transformation  <a id = \"3\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Remove Redundant Columns  <a id = \"3.1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+---------------+----------------------+------------+\n",
      "|      town|flat_type|    flat_model|remaining_lease|floor_area_sqm_imputed|resale_price|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+\n",
      "|ANG MO KIO|   2 ROOM|      Improved|            736|                  44.0|    232000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            727|                  67.0|    250000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    262000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            745|                  68.0|    265000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    265000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            756|                  68.0|    275000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    280000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            700|                  67.0|    285000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    285000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            736|                  67.0|    285000.0|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_imputed = df_imputed.select('town', 'flat_type', 'flat_model', 'remaining_lease', 'floor_area_sqm_imputed', \n",
    "                               'resale_price')\n",
    "df_imputed.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Outlier Removal  <a id = \"3.2\"></a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "reference: https://github.com/Rajshekar-2021/Outlier-Detection-PYSPARK/blob/main/Customer_Data_Outliers_pyspark.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(df):\n",
    "\n",
    "    # Identifying the numerical columns in a spark dataframe\n",
    "    numeric_columns = [column[0] for column in df.dtypes if column[1] in ['int', 'double']]\n",
    "\n",
    "    # Using the `for` loop to create new columns by identifying the outliers for each feature\n",
    "    for column in numeric_columns:\n",
    "\n",
    "        less_Q1 = 'less_Q1_{}'.format(column)\n",
    "        more_Q3 = 'more_Q3_{}'.format(column)\n",
    "        Q1 = 'Q1_{}'.format(column)\n",
    "        Q3 = 'Q3_{}'.format(column)\n",
    "\n",
    "        # Q1 : First Quartile ., Q3 : Third Quartile\n",
    "        Q1 = df.approxQuantile(column, [0.25], relativeError=0)\n",
    "        Q3 = df.approxQuantile(column, [0.75], relativeError=0)\n",
    "        \n",
    "        # IQR : Inter Quantile Range\n",
    "        # We need to define the index [0], as Q1 & Q3 are a set of lists., to perform a mathematical operation\n",
    "        # Q1 & Q3 are defined seperately so as to have a clear indication on First Quantile & 3rd Quantile\n",
    "        IQR = Q3[0] - Q1[0]\n",
    "        \n",
    "        #selecting the data, with -1.5*IQR to + 1.5*IQR., where param = 1.5 default value\n",
    "        less_Q1 =  Q1[0] - 1.5*IQR\n",
    "        more_Q3 =  Q3[0] + 1.5*IQR\n",
    "        \n",
    "        isOutlierCol = 'is_outlier_{}'.format(column)\n",
    "        \n",
    "        df = df.withColumn(isOutlierCol, f.when((df[column] > more_Q3) | (df[column] < less_Q1), 1).otherwise(0))\n",
    "    \n",
    "    # Selecting the specific columns which we have added above, to check if there are any outliers\n",
    "    selected_columns = [column for column in df.columns if column.startswith(\"is_outlier\")]\n",
    "\n",
    "    # Adding all the outlier columns into a new colum \"total_outliers\", to see the total number of outliers\n",
    "    df = df.withColumn('total_outliers', sum(df[column] for column in selected_columns))\n",
    "\n",
    "    # Dropping the extra columns created above, just to create nice dataframe., without extra columns\n",
    "    df = df.drop(*[column for column in df.columns if column.startswith(\"is_outlier\")])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+---------------+----------------------+------------+--------------+\n",
      "|      town|flat_type|    flat_model|remaining_lease|floor_area_sqm_imputed|resale_price|total_outliers|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+--------------+\n",
      "|ANG MO KIO|   2 ROOM|      Improved|            736|                  44.0|    232000.0|             0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            727|                  67.0|    250000.0|             0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    262000.0|             0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            745|                  68.0|    265000.0|             0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    265000.0|             0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            756|                  68.0|    275000.0|             0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    280000.0|             0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            700|                  67.0|    285000.0|             0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    285000.0|             0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            736|                  67.0|    285000.0|             0|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe that shows the number of outliers\n",
    "new_df = find_outliers(df_imputed)\n",
    "new_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+---------------+----------------------+------------+\n",
      "|      town|flat_type|    flat_model|remaining_lease|floor_area_sqm_imputed|resale_price|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+\n",
      "|ANG MO KIO|   2 ROOM|      Improved|            736|                  44.0|    232000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            727|                  67.0|    250000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    262000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            745|                  68.0|    265000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    265000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            756|                  68.0|    275000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    280000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            700|                  67.0|    285000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    285000.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            736|                  67.0|    285000.0|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creates a new dataframe that filters out outliers based on a threshhold\n",
    "df2 = new_df.filter(new_df['total_Outliers'] == 0)\n",
    "\n",
    "# Filter out total_outliers column\n",
    "df2 = df2.drop('total_outliers')\n",
    "\n",
    "# Show dataframe\n",
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64247"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the original row count\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61430"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show row count after outlier removal\n",
    "# Original row count was 64247\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows removed: 2817\n"
     ]
    }
   ],
   "source": [
    "# Show how many rows were removed\n",
    "print(f'Number of rows removed: {df.count() - df2.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Check for Rare Values  <a id = \"3.3\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|       flat_type|count|\n",
      "+----------------+-----+\n",
      "|          4 ROOM|26102|\n",
      "|          3 ROOM|15571|\n",
      "|          5 ROOM|14456|\n",
      "|       EXECUTIVE| 4386|\n",
      "|          2 ROOM|  911|\n",
      "|MULTI-GENERATION|    4|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique values in flat_type\n",
    "df2.groupby('flat_type').count().alias('Count').sort(f.desc('Count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|flat_type|count|\n",
      "+---------+-----+\n",
      "|   4 ROOM|26102|\n",
      "|   3 ROOM|15571|\n",
      "|   5 ROOM|14456|\n",
      "|EXECUTIVE| 4386|\n",
      "|     RARE|  915|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace values with <1000 count\n",
    "# 2 ROOM, MULTI-GENERATION\n",
    "temp:list = [\"2 ROOM\", \"MULTI-GENERATION\"]\n",
    "\n",
    "# Replace rare values\n",
    "df2 = df2.replace(temp, \"RARE\", 'flat_type')\n",
    "\n",
    "df2.groupby('flat_type').count().alias('Count').sort(f.desc('Count')).show(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|           town|count|\n",
      "+---------------+-----+\n",
      "|       SENGKANG| 4970|\n",
      "|    JURONG WEST| 4944|\n",
      "|      WOODLANDS| 4798|\n",
      "|         YISHUN| 4287|\n",
      "|       TAMPINES| 4007|\n",
      "|        PUNGGOL| 4006|\n",
      "|          BEDOK| 3369|\n",
      "|        HOUGANG| 2927|\n",
      "|     ANG MO KIO| 2763|\n",
      "|  CHOA CHU KANG| 2657|\n",
      "|    BUKIT BATOK| 2443|\n",
      "|  BUKIT PANJANG| 2382|\n",
      "|    BUKIT MERAH| 2107|\n",
      "|      PASIR RIS| 1826|\n",
      "|      TOA PAYOH| 1824|\n",
      "|      SEMBAWANG| 1754|\n",
      "|KALLANG/WHAMPOA| 1726|\n",
      "|        GEYLANG| 1470|\n",
      "|    JURONG EAST| 1416|\n",
      "|     QUEENSTOWN| 1415|\n",
      "|       CLEMENTI| 1300|\n",
      "|      SERANGOON| 1263|\n",
      "|         BISHAN|  976|\n",
      "|   CENTRAL AREA|  364|\n",
      "|  MARINE PARADE|  325|\n",
      "|    BUKIT TIMAH|  111|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupby('town').count().alias('Count').sort(f.desc('Count')).show(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|           town|count|\n",
      "+---------------+-----+\n",
      "|       SENGKANG| 4970|\n",
      "|    JURONG WEST| 4944|\n",
      "|      WOODLANDS| 4798|\n",
      "|         YISHUN| 4287|\n",
      "|       TAMPINES| 4007|\n",
      "|        PUNGGOL| 4006|\n",
      "|          BEDOK| 3369|\n",
      "|        HOUGANG| 2927|\n",
      "|     ANG MO KIO| 2763|\n",
      "|  CHOA CHU KANG| 2657|\n",
      "|    BUKIT BATOK| 2443|\n",
      "|  BUKIT PANJANG| 2382|\n",
      "|    BUKIT MERAH| 2107|\n",
      "|      PASIR RIS| 1826|\n",
      "|      TOA PAYOH| 1824|\n",
      "|           RARE| 1776|\n",
      "|      SEMBAWANG| 1754|\n",
      "|KALLANG/WHAMPOA| 1726|\n",
      "|        GEYLANG| 1470|\n",
      "|    JURONG EAST| 1416|\n",
      "|     QUEENSTOWN| 1415|\n",
      "|       CLEMENTI| 1300|\n",
      "|      SERANGOON| 1263|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace values with <1000 count\n",
    "# BISHAN, CENTRAL AREA, MARINE PARADE, BUKIT TIMAH\n",
    "temp:list = [\"BISHAN\", \"CENTRAL AREA\", \"MARINE PARADE\", \"BUKIT TIMAH\"]\n",
    "\n",
    "# Replace rare values\n",
    "df2 = df2.replace(temp, \"RARE\", 'town')\n",
    "\n",
    "df2.groupby('town').count().alias('Count').sort(f.desc('Count')).show(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|         flat_model|count|\n",
      "+-------------------+-----+\n",
      "|            Model A|20434|\n",
      "|           Improved|15279|\n",
      "|     New Generation| 9068|\n",
      "|  Premium Apartment| 6896|\n",
      "|         Simplified| 2754|\n",
      "|          Apartment| 2224|\n",
      "|           Standard| 1692|\n",
      "|         Maisonette| 1565|\n",
      "|           Model A2|  885|\n",
      "|               DBSS|  441|\n",
      "| Model A-Maisonette|   76|\n",
      "|      Adjoined flat|   76|\n",
      "|            Terrace|   19|\n",
      "|Improved-Maisonette|   13|\n",
      "|   Multi Generation|    4|\n",
      "| Premium Maisonette|    4|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupby('flat_model').count().alias('Count').sort(f.desc('Count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|       flat_model|count|\n",
      "+-----------------+-----+\n",
      "|          Model A|20434|\n",
      "|         Improved|15279|\n",
      "|   New Generation| 9068|\n",
      "|Premium Apartment| 6896|\n",
      "|       Simplified| 2754|\n",
      "|        Apartment| 2224|\n",
      "|         Standard| 1692|\n",
      "|       Maisonette| 1565|\n",
      "|         Model A2|  885|\n",
      "|             RARE|  633|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace values with <500 count\n",
    "# DBSS, Adjoined flat, Model A-Maisonette, Terrace, Improved-Maisonette, Premium Maisonette, Multi Generation\n",
    "temp:list = [\"DBSS\", \"Adjoined flat\", \"Model A-Maisonette\", \"Terrace\", \"Improved-Maisonette\", \"Premium Maisonette\", \n",
    "             \"Multi Generation\"]\n",
    "\n",
    "# Replace rare values\n",
    "df2 = df2.replace(temp, \"RARE\", 'flat_model')\n",
    "\n",
    "df2.groupby('flat_model').count().alias('Count').sort(f.desc('Count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 StringIndex <a id = \"3.4\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indexer\n",
    "strings_used:list = [\"town\", \"flat_type\", \"flat_model\"]\n",
    "stage_string:list = [StringIndexer(inputCol = c, outputCol = c + \"_string_encoded\") for c in strings_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+---------------+----------------------+------------+-------------------+------------------------+-------------------------+\n",
      "|      town|flat_type|    flat_model|remaining_lease|floor_area_sqm_imputed|resale_price|town_string_encoded|flat_type_string_encoded|flat_model_string_encoded|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+-------------------+------------------------+-------------------------+\n",
      "|ANG MO KIO|     RARE|      Improved|            736|                  44.0|    232000.0|                8.0|                     4.0|                      1.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            727|                  67.0|    250000.0|                8.0|                     1.0|                      2.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    262000.0|                8.0|                     1.0|                      2.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            745|                  68.0|    265000.0|                8.0|                     1.0|                      2.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    265000.0|                8.0|                     1.0|                      2.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            756|                  68.0|    275000.0|                8.0|                     1.0|                      2.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    280000.0|                8.0|                     1.0|                      2.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            700|                  67.0|    285000.0|                8.0|                     1.0|                      2.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    285000.0|                8.0|                     1.0|                      2.0|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            736|                  67.0|    285000.0|                8.0|                     1.0|                      2.0|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+-------------------+------------------------+-------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline(stages = stage_string)\n",
    "\n",
    "# index string columns\n",
    "df_string_indexed = pipeline.fit(df2).transform(df2)\n",
    "\n",
    "# show new dataframe\n",
    "df_string_indexed.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 OHE <a id = \"3.5\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+---------------+----------------------+------------+-------------------+------------------------+-------------------------+--------------+-----------------+------------------+\n",
      "|      town|flat_type|    flat_model|remaining_lease|floor_area_sqm_imputed|resale_price|town_string_encoded|flat_type_string_encoded|flat_model_string_encoded|  town_one_hot|flat_type_one_hot|flat_model_one_hot|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+-------------------+------------------------+-------------------------+--------------+-----------------+------------------+\n",
      "|ANG MO KIO|     RARE|      Improved|            736|                  44.0|    232000.0|                8.0|                     4.0|                      1.0|(22,[8],[1.0])|        (4,[],[])|     (9,[1],[1.0])|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            727|                  67.0|    250000.0|                8.0|                     1.0|                      2.0|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    262000.0|                8.0|                     1.0|                      2.0|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            745|                  68.0|    265000.0|                8.0|                     1.0|                      2.0|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            749|                  67.0|    265000.0|                8.0|                     1.0|                      2.0|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            756|                  68.0|    275000.0|                8.0|                     1.0|                      2.0|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    280000.0|                8.0|                     1.0|                      2.0|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            700|                  67.0|    285000.0|                8.0|                     1.0|                      2.0|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            738|                  68.0|    285000.0|                8.0|                     1.0|                      2.0|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|ANG MO KIO|   3 ROOM|New Generation|            736|                  67.0|    285000.0|                8.0|                     1.0|                      2.0|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|\n",
      "+----------+---------+--------------+---------------+----------------------+------------+-------------------+------------------------+-------------------------+--------------+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create encoder\n",
    "stage_one_hot:list = [OneHotEncoder(inputCol = c + \"_string_encoded\", outputCol = c + \"_one_hot\") for c in strings_used]\n",
    "\n",
    "# create pipeline\n",
    "ppl = Pipeline(stages = stage_one_hot)\n",
    "\n",
    "# encode string columns\n",
    "df_ohe = ppl.fit(df_string_indexed).transform(df_string_indexed)\n",
    "\n",
    "# show new dataframe\n",
    "df_ohe.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Consolidating X columns <a id = \"3.6\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------+--------------+-----------------+------------------+------------+--------------------+\n",
      "|floor_area_sqm_imputed|remaining_lease|  town_one_hot|flat_type_one_hot|flat_model_one_hot|resale_price|               Xcols|\n",
      "+----------------------+---------------+--------------+-----------------+------------------+------------+--------------------+\n",
      "|                  44.0|            736|(22,[8],[1.0])|        (4,[],[])|     (9,[1],[1.0])|    232000.0|(37,[0,1,10,29],[...|\n",
      "|                  67.0|            727|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    250000.0|(37,[0,1,10,25,30...|\n",
      "|                  67.0|            749|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    262000.0|(37,[0,1,10,25,30...|\n",
      "|                  68.0|            745|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    265000.0|(37,[0,1,10,25,30...|\n",
      "|                  67.0|            749|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    265000.0|(37,[0,1,10,25,30...|\n",
      "|                  68.0|            756|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    275000.0|(37,[0,1,10,25,30...|\n",
      "|                  68.0|            738|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    280000.0|(37,[0,1,10,25,30...|\n",
      "|                  67.0|            700|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    285000.0|(37,[0,1,10,25,30...|\n",
      "|                  68.0|            738|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    285000.0|(37,[0,1,10,25,30...|\n",
      "|                  67.0|            736|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    285000.0|(37,[0,1,10,25,30...|\n",
      "+----------------------+---------------+--------------+-----------------+------------------+------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter dataset to remove original string columns and _string_encoded columns\n",
    "df_vector = df_ohe.select(\"floor_area_sqm_imputed\", \"remaining_lease\", \"town_one_hot\", \n",
    "                          \"flat_type_one_hot\", \"flat_model_one_hot\", \"resale_price\")\n",
    "\n",
    "# Combine x_values into a single column\n",
    "featureassembler = VectorAssembler(inputCols = df_vector.columns[:-1], outputCol = \"Xcols\")\n",
    "df_vector = featureassembler.transform(df_vector)\n",
    "df_vector.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Standard Scaling <a id = \"3.7\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------+--------------+-----------------+------------------+------------+--------------------+--------------------+\n",
      "|floor_area_sqm_imputed|remaining_lease|  town_one_hot|flat_type_one_hot|flat_model_one_hot|resale_price|               Xcols|       Xcols_sscaled|\n",
      "+----------------------+---------------+--------------+-----------------+------------------+------------+--------------------+--------------------+\n",
      "|                  44.0|            736|(22,[8],[1.0])|        (4,[],[])|     (9,[1],[1.0])|    232000.0|(37,[0,1,10,29],[...|[-2.2420629029525...|\n",
      "|                  67.0|            727|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    250000.0|(37,[0,1,10,25,30...|[-1.2611984221375...|\n",
      "|                  67.0|            749|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    262000.0|(37,[0,1,10,25,30...|[-1.2611984221375...|\n",
      "|                  68.0|            745|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    265000.0|(37,[0,1,10,25,30...|[-1.2185521403630...|\n",
      "|                  67.0|            749|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    265000.0|(37,[0,1,10,25,30...|[-1.2611984221375...|\n",
      "|                  68.0|            756|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    275000.0|(37,[0,1,10,25,30...|[-1.2185521403630...|\n",
      "|                  68.0|            738|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    280000.0|(37,[0,1,10,25,30...|[-1.2185521403630...|\n",
      "|                  67.0|            700|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    285000.0|(37,[0,1,10,25,30...|[-1.2611984221375...|\n",
      "|                  68.0|            738|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    285000.0|(37,[0,1,10,25,30...|[-1.2185521403630...|\n",
      "|                  67.0|            736|(22,[8],[1.0])|    (4,[1],[1.0])|     (9,[2],[1.0])|    285000.0|(37,[0,1,10,25,30...|[-1.2611984221375...|\n",
      "+----------------------+---------------+--------------+-----------------+------------------+------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scale data\n",
    "sScaler = StandardScaler(withMean = True, withStd = True, inputCol = \"Xcols\", outputCol = \"Xcols_sscaled\")\n",
    "df_scaled = sScaler.fit(df_vector).transform(df_vector)\n",
    "df_scaled.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Train-test Split <a id = \"3.8\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|       Xcols_sscaled|resale_price|\n",
      "+--------------------+------------+\n",
      "|[-2.2420629029525...|    232000.0|\n",
      "|[-1.2611984221375...|    250000.0|\n",
      "|[-1.2611984221375...|    262000.0|\n",
      "|[-1.2185521403630...|    265000.0|\n",
      "|[-1.2611984221375...|    265000.0|\n",
      "|[-1.2185521403630...|    275000.0|\n",
      "|[-1.2185521403630...|    280000.0|\n",
      "|[-1.2611984221375...|    285000.0|\n",
      "|[-1.2185521403630...|    285000.0|\n",
      "|[-1.2611984221375...|    285000.0|\n",
      "+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create final dataframe that only has Xcols_sscaled and resale_price\n",
    "df_final = df_scaled.select(\"Xcols_sscaled\", \"resale_price\")\n",
    "df_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the train/test split\n",
    "(train, test) = df_final.randomSplit([0.7, 0.3], seed = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Modeling  <a id = \"4\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|       Xcols_sscaled|resale_price|\n",
      "+--------------------+------------+\n",
      "|[-2.4979405935998...|    191000.0|\n",
      "|[-2.4126480300507...|    200000.0|\n",
      "|[-2.4126480300507...|    200000.0|\n",
      "|[-2.4126480300507...|    230000.0|\n",
      "|[-2.4126480300507...|    195000.0|\n",
      "|[-2.4126480300507...|    215000.0|\n",
      "|[-2.4126480300507...|    215000.0|\n",
      "|[-2.4126480300507...|    210000.0|\n",
      "|[-2.4126480300507...|    205000.0|\n",
      "|[-2.4126480300507...|    205000.0|\n",
      "+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train rows: 43013\n",
      "Number of train columns: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of train rows: {train.count()}')\n",
    "print(f'Number of train columns: {len(train.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|       Xcols_sscaled|resale_price|\n",
      "+--------------------+------------+\n",
      "|[-2.5405868753744...|    210000.0|\n",
      "|[-2.4126480300507...|    182000.0|\n",
      "|[-2.4126480300507...|    215000.0|\n",
      "|[-2.4126480300507...|    208000.0|\n",
      "|[-2.4126480300507...|    218000.0|\n",
      "|[-2.3700017482761...|    207000.0|\n",
      "|[-2.3700017482761...|    225000.0|\n",
      "|[-2.3700017482761...|    186000.0|\n",
      "|[-2.3700017482761...|    268000.0|\n",
      "|[-2.3273554665016...|    180000.0|\n",
      "+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train rows: 18417\n",
      "Number of train columns: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of train rows: {test.count()}')\n",
    "print(f'Number of train columns: {len(test.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression(featuresCol = \"Xcols_sscaled\", labelCol = 'resale_price')\n",
    "regressor = regressor.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation and Selection  <a id = \"5\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------------+\n",
      "|       Xcols_sscaled|resale_price|        prediction|\n",
      "+--------------------+------------+------------------+\n",
      "|[-2.4979405935998...|    191000.0|173136.84017379128|\n",
      "|[-2.4126480300507...|    200000.0|175002.35294644226|\n",
      "|[-2.4126480300507...|    200000.0| 175754.9252636602|\n",
      "|[-2.4126480300507...|    230000.0|178765.21453253203|\n",
      "|[-2.4126480300507...|    195000.0|181022.93148418586|\n",
      "|[-2.4126480300507...|    215000.0|181775.50380140386|\n",
      "|[-2.4126480300507...|    215000.0|180208.76546584966|\n",
      "|[-2.4126480300507...|    210000.0|188119.15430662787|\n",
      "|[-2.4126480300507...|    205000.0|186981.91632081135|\n",
      "|[-2.4126480300507...|    205000.0| 248754.4400338022|\n",
      "+--------------------+------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get y_train\n",
    "train_pred_results = regressor.evaluate(train)\n",
    "\n",
    "# show y_train\n",
    "train_pred_results.predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------------+\n",
      "|       Xcols_sscaled|resale_price|        prediction|\n",
      "+--------------------+------------+------------------+\n",
      "|[-2.5405868753744...|    210000.0| 48706.06897278002|\n",
      "|[-2.4126480300507...|    182000.0|178765.21453253203|\n",
      "|[-2.4126480300507...|    215000.0|182904.36227723077|\n",
      "|[-2.4126480300507...|    208000.0|  169718.157503489|\n",
      "|[-2.4126480300507...|    218000.0|170847.01597931597|\n",
      "|[-2.3700017482761...|    207000.0|183775.52496243804|\n",
      "|[-2.3700017482761...|    225000.0| 186409.5280727009|\n",
      "|[-2.3700017482761...|    186000.0|188290.95886574584|\n",
      "|[-2.3700017482761...|    268000.0|279131.85112719826|\n",
      "|[-2.3273554665016...|    180000.0|176438.36536935563|\n",
      "+--------------------+------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get y_test\n",
    "test_pred_results = regressor.evaluate(test)\n",
    "\n",
    "# show y_test\n",
    "test_pred_results.predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 42821.10377449093\n",
      "Train MSE: 3071397777.332468\n",
      "Train R2: 0.8085364266769526\n"
     ]
    }
   ],
   "source": [
    "# Train MAE, MSE, R2\n",
    "train_mae = train_pred_results.meanAbsoluteError\n",
    "train_mse = train_pred_results.meanSquaredError\n",
    "train_r2 = train_pred_results.r2\n",
    "\n",
    "print(f'Train MAE: {train_mae}')\n",
    "print(f'Train MSE: {train_mse}')\n",
    "print(f'Train R2: {train_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 42108.76809618526\n",
      "Test MSE: 2989888821.967632\n",
      "Test R2: 0.8128824075980264\n"
     ]
    }
   ],
   "source": [
    "# Test MAE, MSE, R2\n",
    "test_mae = test_pred_results.meanAbsoluteError\n",
    "test_mse = test_pred_results.meanSquaredError\n",
    "test_r2 = test_pred_results.r2\n",
    "\n",
    "print(f'Test MAE: {test_mae}')\n",
    "print(f'Test MSE: {test_mse}')\n",
    "print(f'Test R2: {test_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Report  <a id = \"6\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Problem Statement Formulation <a id = \"6.1\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report contains the documentation of the analysis and findings from the `sg_flat_prices_mod` dataset. The objectives of this report are:\n",
    "\n",
    "- To formulate a problem statement, conduct data preparation, exploration, and analysis through visualisation and statistical methods\n",
    "- To prepare the data ready for machine learning\n",
    "\n",
    "This report will also explain problems for each dataset, the steps taken, and solutions used to modify the datasets.\n",
    "\n",
    "\n",
    "After loading the data, the `.printSchema()` function shows the data type of each column and shows that some are strings, integers, and doubles.\n",
    "\n",
    "This notebook will explore which columns are significant in affecting resale_price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Exploratory Data Analysis and Data Cleansing <a id = \"6.2\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon loading the data, `df.select([f.count(f.when(f.isnan(c) | f.col(c).isNull(), c)).alias(c) for c in df.columns]).show()` is used to check for null values. From here, it is observed that `floor_area_sqm` contains 50 nulls.\n",
    "\n",
    "An Imputer is used to replace the null values with the median because it is unaffected by extreme values. Using the same code as before to show the null values, a new column is shown called `floor_area_sqm_imputed` which contains 0 null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Data Wrangling and Transformation <a id = \"6.3\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Redundant Columns\n",
    "\n",
    "After removing null values, the columns `year`, `month`, `block`, `street_name`, and `story_range` are redundant and can be removed.\n",
    "\n",
    "### Outlier Removal\n",
    "\n",
    "reference: https://github.com/Rajshekar-2021/Outlier-Detection-PYSPARK/blob/main/Customer_Data_Outliers_pyspark.ipynb\n",
    "\n",
    "A method called find_outliers() is created. This method finds any outliers in a row and adds an outlier count at the last column\n",
    "\n",
    "Outliers are then removed by filtering rows with outlier count is more than 0. After removal, the final row count is 61430. The orginal row count was 64247, so this process removed 2817 rows.\n",
    "\n",
    "### Check for Rare Values\n",
    "\n",
    "Next, the dataframe is checked for rare values. The number of unique values in `flat_type` is shown and the values `2 ROOM` and `MULTI-GENERATION` can be replaced with `RARE` since their counts are less than 1000. \n",
    "\n",
    "The next column to be checked is `town`. `BISHAN`, `CENTRAL AREA`, `MARINE PARADE`, and `BUKIT TIMAH` can be replaced with `RARE` since their counts are also less than 1000. \n",
    "\n",
    "In `flat_model`, `DBSS`, `Adjoined flat`, `Model A-Maisonette`, `Terrace`, `Multi Generation`, `Improved-Maisonette`, and `Premium Maisonette` can be replaced with `RARE` as their counts are less than 500.\n",
    "\n",
    "### StringIndex\n",
    "\n",
    "After checking for rare values, the string columns are mapped to integers using a StringIndexer.\n",
    "\n",
    "### OHE\n",
    "\n",
    "After mapping the strings to integers, a One Hot Encoder is applied.\n",
    "\n",
    "### Consolidating X Columns\n",
    "\n",
    "After OHE, a new column (Xcols) is created which contains all the X-values (`town`, `flat_type`, `flat_model`, `remaining_lease`, `floor_area_sqm_imputed`).\n",
    "\n",
    "### Standard Scaling\n",
    "\n",
    "Next, a z-transformation is applied to Xcols and a new column (Xcols_sscaled) is created.\n",
    "\n",
    "### Train-test Split\n",
    "\n",
    "After scaling the values, the dataframe is filtered to only have `Xcols_sscaled` and `resale_price`. It is then split into train (70%) and test (30%) sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 Machine Learning Modelling <a id = \"6.4\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows and columns of the train and test sets are shown.\n",
    "\n",
    "- Number of train rows: 45007\n",
    "- Number of train columns: 2\n",
    "\n",
    "\n",
    "- Number of test rows: 19240\n",
    "- Number of test columns: 2\n",
    "\n",
    "Since the target column `resale_price` has continuous values, a linear regressor is created. Its features columns will be `Xcol_sscaled`, and the label column will be `resale_price`.\n",
    "\n",
    "Finally, the regressor is fitted onto the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Model Evaluation and Selection <a id = \"6.5\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the regressor, the predicted y_train and predicted y_test are calculated.\n",
    "\n",
    "Using these results, the MAE, MSE, and R2 values can be found.\n",
    "\n",
    "- Train MAE: 42821.10377449093\n",
    "- Train MSE: 3071397777.332468\n",
    "- Train R2: 0.8085364266769526\n",
    "\n",
    "\n",
    "- Test MAE: 42108.76809618526\n",
    "- Test MSE: 2989888821.967632\n",
    "- Test R2: 0.8128824075980264\n",
    "\n",
    "From here, it is observed that the test set had better scores than the train set. The test had lower MAE, MSE, and higher R2 scores than the train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Summary and Further Improvements <a id = \"6.6\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using Pandas and its related libraries, the notebook could not use matplotlib or seaborn visualisations to aid data exploration and wrangling. This limitation affected forms of data representation and the discovery of data insights and correlation.\n",
    "\n",
    "For example, a heatmap could have helped show data correlation. Or using a kdeplot or histogram could show data distribution.\n",
    "\n",
    "Additionally, a library called `statsmodels.api` has an Ordinary Least Squares (OLS) function that builds a model and shows which columns are significant in predicting `resale_price`. The OLS model is beneficial as it identifies removable columns to avoid overfitting the regressor model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. \"Unlisted\" Youtube Link to Video Presentation  <a id = \"7\"></a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your link in this cell, you are allowed to comment it out\n",
    "# youtube link: https://youtu.be/aChC1QdI-5A "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
